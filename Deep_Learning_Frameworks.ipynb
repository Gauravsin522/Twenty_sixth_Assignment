{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5450385b",
      "metadata": {
        "id": "5450385b"
      },
      "source": [
        "# Deep Learning Frameworks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b9a3c73",
      "metadata": {
        "id": "1b9a3c73"
      },
      "outputs": [],
      "source": [
        "# 1. What is TensorFlow 2.0, and how is it different from TensorFlow 1.x2?\n",
        "\n",
        "# TensorFlow 2.0 is a major update to the TensorFlow library, which is widely used for machine learning and deep learning tasks.\n",
        "# The key differences between TensorFlow 2.0 and its predecessor, TensorFlow 1.x, include:\n",
        "\n",
        "# 1. Eager Execution: TensorFlow 2.0 enables eager execution by default, allowing for immediate evaluation of operations and making\n",
        "# it easier to debug and iterate on models.\n",
        "# In TensorFlow 1.x, a static computation graph was built first, and then executed in\n",
        "# a separate session, which made debugging more complex.\n",
        "# 2. Simplified API: TensorFlow 2.0 provides a more user-friendly and intuitive API, making it easier for developers to build and train models.\n",
        "# The Keras API is integrated into TensorFlow 2.0, allowing for a more streamlined experience when building neural networks.\n",
        "# 3. tf.function: TensorFlow 2.0 introduces the tf.function decorator, which allows users to convert Python functions into TensorFlow graphs,\n",
        "# enabling better performance while still maintaining the flexibility of eager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a58bc4e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a58bc4e3",
        "outputId": "4903ffd5-a262-482c-af85-b616566ada44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# 2. How do you install TensorFlow 2.0 ?\n",
        "\n",
        "# Answer:\n",
        "# You can install TensorFlow 2.0 using pip. Open your terminal or command prompt and run the following command:\n",
        "# ```bash\n",
        "!pip install tensorflow\n",
        "# ```\n",
        "# Make sure you have the appropriate NVIDIA drivers and CUDA toolkit installed for GPU support.\n",
        "# You can also check the official TensorFlow website for installation instructions and compatibility with your system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2c11f30",
      "metadata": {
        "id": "f2c11f30"
      },
      "outputs": [],
      "source": [
        "# 3. What is the primary function of the tf.function in TensorFlow 2.0 ?\n",
        "\n",
        "# Answer:\n",
        "# The primary function of tf.function in TensorFlow 2.0 is to convert a Python function into a TensorFlow graph.\n",
        "# This allows for better performance and optimization of the function when it is executed multiple times.\n",
        "# By using tf.function, you can take advantage of TensorFlow's graph execution capabilities while still writing code in a more Pythonic way.\n",
        "\n",
        "# This is particularly useful for training and inference in machine learning models, as it can lead to significant speedups compared to eager execution.\n",
        "# The tf.function decorator automatically traces the function's operations and creates a static computation graph,\n",
        "# which can be optimized and executed more efficiently.\n",
        "# Additionally, tf.function allows for better compatibility with TensorFlow's distributed training and deployment features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cab129f3",
      "metadata": {
        "id": "cab129f3"
      },
      "outputs": [],
      "source": [
        "# 4. What is the purpose of the Model class in TensorFlow 2.0?\n",
        "\n",
        "#Answer:\n",
        "# The Model class in TensorFlow 2.0 serves as a base class for building and training machine learning models.\n",
        "# It provides a high-level API for defining, compiling, and training models, making it easier to create complex architectures.\n",
        "# The Model class is part of the Keras API, which is integrated into TensorFlow 2.0.\n",
        "# Some key features of the Model class include:\n",
        "# 1. Layer Composition: The Model class allows you to easily stack layers together to create a neural network architecture.\n",
        "# You can use the Sequential model for linear stacks of layers or the Functional API for more complex architectures with multiple inputs and outputs.\n",
        "# 2. Compilation: The Model class provides methods for compiling the model, specifying the optimizer, loss function, and evaluation metrics.\n",
        "# This simplifies the process of preparing the model for training.\n",
        "# 3. Training and Evaluation: The Model class includes methods for training the model (fit), evaluating its performance (evaluate),\n",
        "# and making predictions (predict). These methods handle the training loop, including batching, shuffling, and validation.\n",
        "# 4. Callbacks: The Model class supports callbacks, which are functions that can be called at various stages of training.\n",
        "# This allows you to implement custom behavior, such as saving the model, adjusting the learning rate, or early stopping.\n",
        "# 5. Saving and Loading: The Model class provides methods for saving and loading the model architecture, weights, and training configuration.\n",
        "# This makes it easy to save your work and resume training later or deploy the model for inference.\n",
        "# Overall, the Model class in TensorFlow 2.0 simplifies the process of building and training machine learning models,\n",
        "# allowing developers to focus on the design and implementation of their models rather than the underlying mechanics of training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2d4d8c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2d4d8c6",
        "outputId": "52b95b83-b105-4e0c-8de2-873f09f4684f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5105 - loss: 0.6956 - val_accuracy: 0.4350 - val_loss: 0.7019\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4905 - loss: 0.6959 - val_accuracy: 0.4250 - val_loss: 0.7067\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5078 - loss: 0.6906 - val_accuracy: 0.4700 - val_loss: 0.7013\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5697 - loss: 0.6835 - val_accuracy: 0.4850 - val_loss: 0.6979\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5723 - loss: 0.6831 - val_accuracy: 0.4800 - val_loss: 0.6992\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6195 - loss: 0.6794 - val_accuracy: 0.4600 - val_loss: 0.7077\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5924 - loss: 0.6781 - val_accuracy: 0.4750 - val_loss: 0.7111\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5975 - loss: 0.6738 - val_accuracy: 0.4850 - val_loss: 0.7023\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6072 - loss: 0.6724 - val_accuracy: 0.4750 - val_loss: 0.7095\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6163 - loss: 0.6672 - val_accuracy: 0.4700 - val_loss: 0.7118\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6346 - loss: 0.6672 \n",
            "Test accuracy: 0.597000002861023\n"
          ]
        }
      ],
      "source": [
        "# 5. How do you create a neural network using TensorFlow 2.0?\n",
        "\n",
        "# Answer:\n",
        "# To create a neural network using TensorFlow 2.0, you can use the Keras API, which is integrated into TensorFlow.\n",
        "# Here's a simple example of how to create a feedforward neural network using the Sequential model:\n",
        "\n",
        "# ```python\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "\n",
        "# Generate some random data for demonstration\n",
        "x_train = np.random.rand(1000, 20)  # 1000 samples, 20 features\n",
        "y_train = np.random.randint(0, 2, size=(1000, 1))  # Binary classification\n",
        "\n",
        "# Create a Sequential model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(20,)))  # Input layer\n",
        "model.add(layers.Dense(64, activation='relu'))  # Hidden layer\n",
        "model.add(layers.Dense(1, activation='sigmoid'))  # Output layer\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(x_train, y_train)\n",
        "print(f'Test accuracy: {test_accuracy}')\n",
        "# ```\n",
        "# In this example, we create a simple feedforward neural network with two hidden layers using the Sequential model.\n",
        "# We compile the model with the Adam optimizer and binary crossentropy loss function for binary classification.\n",
        "# Finally, we train the model on random data and evaluate its performance.\n",
        "# You can customize the architecture, activation functions, and other parameters based on your specific use case.\n",
        "# The Keras API also allows you to create more complex architectures using the Functional API if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0685fb09",
      "metadata": {
        "id": "0685fb09"
      },
      "outputs": [],
      "source": [
        "# 6. What is the importance of Tensor Space in TensorFlow?\n",
        "\n",
        "# Answer:\n",
        "# Tensor space is a fundamental concept in TensorFlow, as it provides the mathematical framework for representing and manipulating data.\n",
        "# Tensors are multi-dimensional arrays that generalize scalars, vectors, and matrices to higher dimensions.\n",
        "# The importance of tensor space in TensorFlow includes:\n",
        "# 1. Data Representation: Tensors are the primary data structure in TensorFlow, allowing for efficient representation of various types of data,\n",
        "# including images, text, and time series. Each tensor has a shape that defines its dimensions and the number of elements it contains.\n",
        "# 2. Mathematical Operations: Tensor space enables the definition of mathematical operations on tensors, such as addition, multiplication,\n",
        "# and matrix operations. TensorFlow provides a wide range of built-in functions for performing these operations efficiently.\n",
        "# 3. Automatic Differentiation: Tensor space is essential for automatic differentiation, which is a key feature of TensorFlow.\n",
        "# TensorFlow can compute gradients of functions with respect to their inputs, enabling efficient optimization of machine learning models.\n",
        "# This is particularly important for training neural networks using gradient descent and backpropagation.\n",
        "# 4. GPU Acceleration: Tensor space allows TensorFlow to leverage GPU acceleration for performing tensor operations in parallel.\n",
        "# This significantly speeds up computations, especially for large-scale machine learning tasks.\n",
        "# 5. Flexibility: Tensor space provides a flexible framework for defining complex data structures and operations,\n",
        "# allowing developers to create custom models and algorithms.\n",
        "# TensorFlow's support for dynamic shapes and broadcasting makes it easier to work with tensors of varying dimensions.\n",
        "# 6. Interoperability: Tensor space enables interoperability with other libraries and frameworks in the machine learning ecosystem.\n",
        "# Tensors can be easily converted to and from NumPy arrays, making it easy to integrate TensorFlow with other scientific computing libraries.\n",
        "# Overall, tensor space is a foundational concept in TensorFlow that underpins its functionality and performance,\n",
        "# enabling efficient representation, manipulation, and optimization of data in machine learning and deep learning applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "298e8adc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "298e8adc",
        "outputId": "53373bda-d4f6-445d-aea5-036fb416bef5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.5233 - loss: 0.6946 - val_accuracy: 0.4550 - val_loss: 0.7051\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5227 - loss: 0.6905 - val_accuracy: 0.4800 - val_loss: 0.7002\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5388 - loss: 0.6850 - val_accuracy: 0.5000 - val_loss: 0.7010\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5320 - loss: 0.6850 - val_accuracy: 0.4750 - val_loss: 0.7062\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5513 - loss: 0.6892 - val_accuracy: 0.4550 - val_loss: 0.7079\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5753 - loss: 0.6825 - val_accuracy: 0.4800 - val_loss: 0.7088\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5813 - loss: 0.6801 - val_accuracy: 0.4500 - val_loss: 0.7161\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6186 - loss: 0.6716 - val_accuracy: 0.5000 - val_loss: 0.7044\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5987 - loss: 0.6712 - val_accuracy: 0.4800 - val_loss: 0.7043\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5857 - loss: 0.6714 - val_accuracy: 0.5150 - val_loss: 0.7021\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c77e9b74dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# 7. How can TensorBoard be integrated with TensorFlow 2.0?\n",
        "\n",
        "# Answer:\n",
        "# TensorBoard is a powerful visualization tool that allows you to monitor and analyze your TensorFlow models during training.\n",
        "# In TensorFlow 2.0, integrating TensorBoard is straightforward, especially when using the Keras API. Here's how to do it:\n",
        "\n",
        "# 1. Import the necessary libraries:\n",
        "# ```python\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import numpy as np\n",
        "import datetime\n",
        "# ```\n",
        "# 2. Generate some random data for demonstration:\n",
        "# ```python\n",
        "x_train = np.random.rand(1000, 20)  # 1000 samples, 20 features\n",
        "y_train = np.random.randint(0, 2, size=(1000, 1))  # Binary classification\n",
        "# ```\n",
        "# 3. Create a Sequential model:\n",
        "# ```python\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(20,)))  # Input layer\n",
        "model.add(layers.Dense(64, activation='relu'))  # Hidden layer\n",
        "model.add(layers.Dense(1, activation='sigmoid'))  # Output layer\n",
        "# ```\n",
        "# 4. Compile the model:\n",
        "# ```python\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# ```\n",
        "# 5. Set up TensorBoard callback:\n",
        "# ```python\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "# ```\n",
        "# 6. Train the model with TensorBoard callback:\n",
        "# ```python\n",
        "model.fit(x_train, y_train,\n",
        "          epochs=10,\n",
        "          batch_size=32,\n",
        "          validation_split=0.2,\n",
        "          callbacks=[tensorboard_callback])\n",
        "# ```\n",
        "# 7. Launch TensorBoard:\n",
        "# After training, you can launch TensorBoard to visualize the training process. Open a terminal and run:\n",
        "# ```bash\n",
        "# tensorboard --logdir=logs/fit\n",
        "# ```\n",
        "# Then, open your web browser and go to `http://localhost:6006` to view the TensorBoard dashboard.\n",
        "# You can monitor various metrics such as loss, accuracy, and histograms of weights and biases during training.\n",
        "# TensorBoard also provides tools for visualizing model graphs, distributions, and more.\n",
        "# This integration allows you to gain insights into your model's performance and make informed decisions during the training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28948a3b",
      "metadata": {
        "id": "28948a3b"
      },
      "outputs": [],
      "source": [
        "# 8. What is the purpose of TensorFlow Playground?\n",
        "\n",
        "# Answer:\n",
        "# TensorFlow Playground is an interactive web-based tool that allows users to experiment with and visualize neural networks in a simplified environment.\n",
        "# It is designed to help users understand the concepts of machine learning and neural networks without requiring any programming or installation.\n",
        "# The main purposes of TensorFlow Playground include:\n",
        "# 1. Educational Tool: TensorFlow Playground serves as an educational resource for beginners and those new to machine learning.\n",
        "# It provides a hands-on experience for learning about neural networks, activation functions, and optimization techniques.\n",
        "# Users can experiment with different configurations and observe how changes affect the model's performance.\n",
        "# 2. Visualization: The tool provides visualizations of the neural network architecture, including the layers, neurons, and connections.\n",
        "# Users can see how the model learns from data by visualizing decision boundaries and the impact of different hyperparameters.\n",
        "# 3. Experimentation: TensorFlow Playground allows users to experiment with various hyperparameters, such as the number of layers,\n",
        "# number of neurons, learning rate, and activation functions.\n",
        "# Users can observe how these changes affect the model's ability to learn and generalize from the data.\n",
        "# 4. Intuitive Interface: The web-based interface is user-friendly and intuitive, making it accessible to a wide audience.\n",
        "# Users can easily adjust parameters using sliders and buttons, making it easy to explore different configurations.\n",
        "# 5. No Setup Required: TensorFlow Playground runs in the browser, eliminating the need for installation or setup.\n",
        "# This makes it convenient for users to start experimenting with neural networks immediately.\n",
        "# 6. Understanding Concepts: By using TensorFlow Playground, users can gain a better understanding of key concepts in machine learning,\n",
        "# such as overfitting, underfitting, and the impact of different activation functions on model performance.\n",
        "# Overall, TensorFlow Playground is a valuable tool for learning and experimenting with neural networks in a visual and interactive way.\n",
        "# It helps users grasp the fundamental concepts of machine learning and neural networks before diving into more complex implementations using TensorFlow or other libraries.\n",
        "# The tool is particularly useful for educators, students, and anyone interested in gaining a deeper understanding of how neural networks work.\n",
        "# TensorFlow Playground can be accessed at the following URL: https://playground.tensorflow.org/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "931d2b08",
      "metadata": {
        "id": "931d2b08"
      },
      "outputs": [],
      "source": [
        "# 9. What is Netron, and how is it useful for deep learning models?\n",
        "\n",
        "# Answer:\n",
        "# Netron is an open-source viewer for neural network models. It provides a graphical interface for visualizing and analyzing deep learning models,\n",
        "# making it easier to understand their architecture and structure.\n",
        "# Netron supports various model formats, including TensorFlow, Keras, PyTorch, ONNX, Caffe, and more.\n",
        "# It is available as a web application and can also be installed as a desktop application for Windows, macOS, and Linux.\n",
        "# The main purposes and features of Netron include:\n",
        "# 1. Model Visualization: Netron allows users to visualize the architecture of deep learning models in a clear and intuitive way.\n",
        "# Users can see the layers, operations, and connections between them, making it easier to understand how the model processes data.\n",
        "# 2. Layer Details: Users can click on individual layers to view detailed information about their parameters, shapes, and configurations.\n",
        "# This helps in understanding the role of each layer in the model and how they contribute to the overall architecture.\n",
        "# 3. Model Debugging: Netron can be useful for debugging and troubleshooting deep learning models.\n",
        "# By visualizing the model, users can identify potential issues, such as incorrect layer connections or unexpected shapes.\n",
        "# This can help in diagnosing problems during model development and training.\n",
        "# 4. Model Comparison: Netron allows users to compare different versions of models or different architectures side by side.\n",
        "# This can be helpful when experimenting with different designs or when trying to understand the differences between various models.\n",
        "# 5. Export and Import: Netron supports various model formats, making it easy to import models from different frameworks and export them for use in other applications.\n",
        "# This interoperability is beneficial for researchers and developers working with multiple deep learning libraries.\n",
        "# 6. Documentation: Netron can serve as a form of documentation for deep learning models, providing a visual representation of the architecture.\n",
        "# This can be useful for sharing models with others or for future reference.\n",
        "# 7. Accessibility: Netron is available as a web application, making it easy to access and use without requiring installation.\n",
        "# The desktop version can be installed for offline use.\n",
        "# This flexibility allows users to visualize models on different platforms.\n",
        "# Overall, Netron is a valuable tool for anyone working with deep learning models.\n",
        "# It simplifies the process of understanding, debugging, and documenting neural network architectures,\n",
        "# making it easier for researchers, developers, and educators to work with complex models.\n",
        "# By providing a clear and interactive visualization of model structures, Netron enhances the workflow of deep learning practitioners and helps them gain insights into their models.\n",
        "# Netron can be accessed at the following URL: https://netron.app/\n",
        "# It can also be installed as a desktop application from the same website."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4053c914",
      "metadata": {
        "id": "4053c914"
      },
      "outputs": [],
      "source": [
        "# 10. What is the difference between TensorFlow and PyTorch?\n",
        "\n",
        "# Answer:\n",
        "# TensorFlow and PyTorch are two of the most popular deep learning frameworks, each with its own strengths and weaknesses.\n",
        "# Here are some key differences between TensorFlow and PyTorch:\n",
        "# 1. Programming Paradigm:\n",
        "# TensorFlow primarily uses a static computation graph approach, where the computation graph is defined before execution.\n",
        "# This means that you need to build the entire graph before running any operations.\n",
        "# TensorFlow 2.0 introduced eager execution, which allows for dynamic graph execution similar to PyTorch.\n",
        "# However, TensorFlow still retains the option to use static graphs for performance optimization.\n",
        "# PyTorch, on the other hand, uses a dynamic computation graph approach, where the graph is built on-the-fly during execution.\n",
        "# This makes PyTorch more intuitive and easier to debug, as it behaves more like standard Python code.\n",
        "\n",
        "# 2. Ease of Use:\n",
        "# PyTorch is often considered more user-friendly and Pythonic, making it a popular choice for researchers and developers.\n",
        "# TensorFlow, especially in its earlier versions, had a steeper learning curve due to its static graph approach.\n",
        "# TensorFlow 2.0 has improved usability with the integration of the Keras API and eager execution.\n",
        "# 3. Community and Ecosystem:\n",
        "# TensorFlow has a larger ecosystem and more extensive community support, including tools like TensorBoard for visualization\n",
        "# and TensorFlow Lite for deploying models on mobile and embedded devices.\n",
        "# PyTorch has a growing community and ecosystem, with tools like TorchServe for model serving and integration with libraries like Hugging Face.\n",
        "# 4. Performance:\n",
        "# TensorFlow is often considered more optimized for production environments, with better support for distributed training\n",
        "# and deployment on various platforms, including mobile and edge devices.\n",
        "# PyTorch is widely used in research due to its flexibility and ease of experimentation.\n",
        "# 5. Model Deployment:\n",
        "# TensorFlow provides robust tools for deploying models in production, such as TensorFlow Serving and TensorFlow Lite.\n",
        "# PyTorch has made significant strides in this area with TorchScript and ONNX (Open Neural Network Exchange) support.\n",
        "# 6. Debugging:\n",
        "# PyTorch's dynamic computation graph makes it easier to debug models using standard Python debugging tools.\n",
        "# TensorFlow's static graph approach can make debugging more challenging, although eager execution in TensorFlow 2.0 has improved this aspect.\n",
        "# 7. Popularity in Research vs. Industry:\n",
        "# PyTorch is widely adopted in the research community due to its flexibility and ease of use.\n",
        "# TensorFlow is more commonly used in industry for production-grade applications due to its scalability and deployment capabilities.\n",
        "# In summary, the choice between TensorFlow and PyTorch depends on the specific use case and user preferences.\n",
        "# PyTorch is often preferred for research and experimentation, while TensorFlow is favored for production and deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d23b708",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d23b708",
        "outputId": "038a6f00-3604-47ab-8258-44a38117efed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "2.6.0+cu124\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "# 11. How do you install PyTorch?\n",
        "\n",
        "# Answer:\n",
        "# You can install PyTorch using pip or conda, depending on your preference and environment.\n",
        "# The installation command may vary based on your operating system, Python version, and whether you want to use GPU support.\n",
        "# Here are the general steps to install PyTorch:\n",
        "# 1. Visit the official PyTorch website: https://pytorch.org/get-started/locally/\n",
        "# 2. Select your preferences:\n",
        "# - Choose your operating system (Windows, macOS, Linux).\n",
        "# - Select your package manager (pip or conda).\n",
        "# - Choose the language (Python).\n",
        "# - Select the version of CUDA if you want GPU support (or choose \"None\" for CPU only).\n",
        "# 3. Based on your selections, the website will provide you with the appropriate installation command.\n",
        "# 4. Open your terminal or command prompt and run the provided command.\n",
        "# For example, if you want to install PyTorch with CPU support using pip, you might run:\n",
        "# ```bash\n",
        "!pip install torch torchvision torchaudio\n",
        "# ```\n",
        "# If you want to install PyTorch with GPU support (CUDA), the command might look like this:\n",
        "# ```bash\n",
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "# ```\n",
        "# (Note: The CUDA version may vary based on your system and the latest available version.)\n",
        "# 5. Verify the installation:\n",
        "# After installation, you can verify that PyTorch is installed correctly by running the following command in Python:\n",
        "# ```python\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())  # Check if GPU is available\n",
        "# ```\n",
        "# This should print the installed PyTorch version and whether CUDA is available for GPU support.\n",
        "# If you encounter any issues during installation, refer to the official PyTorch documentation for troubleshooting and additional instructions.\n",
        "# The documentation provides detailed information on installation options, compatibility, and system requirements.\n",
        "# PyTorch is a powerful deep learning framework that is widely used for research and production applications.\n",
        "# It offers a flexible and intuitive interface for building and training neural networks, making it a popular choice among researchers and developers.\n",
        "# With its dynamic computation graph and extensive community support, PyTorch has become one of the leading frameworks in the deep learning ecosystem.\n",
        "# Whether you are working on research projects, developing machine learning applications, or deploying models in production,\n",
        "# PyTorch provides the tools and resources you need to succeed.\n",
        "# By following the installation steps outlined above, you can quickly set up PyTorch and start building your own deep learning models.\n",
        "# Whether you are a beginner or an experienced practitioner, PyTorch offers a user-friendly environment for exploring the world of deep learning.\n",
        "# With its rich ecosystem of libraries and tools, PyTorch empowers you to tackle a wide range of machine learning tasks,\n",
        "# from computer vision to natural language processing and beyond."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cace12b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "cace12b7",
        "outputId": "c2cc283c-200a-43c5-ced5-fa51b2782c3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.3519\n",
            "Epoch [20/100], Loss: 0.3638\n",
            "Epoch [30/100], Loss: 0.3848\n",
            "Epoch [40/100], Loss: 0.3470\n",
            "Epoch [50/100], Loss: 0.3478\n",
            "Epoch [60/100], Loss: 0.3766\n",
            "Epoch [70/100], Loss: 0.3450\n",
            "Epoch [80/100], Loss: 0.3450\n",
            "Epoch [90/100], Loss: 0.3446\n",
            "Epoch [100/100], Loss: 0.3136\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8250\n"
          ]
        }
      ],
      "source": [
        "# 12. What is the basic structure of a PyTorch neural network?\n",
        "\n",
        "# Answer:\n",
        "# The basic structure of a PyTorch neural network consists of several key components:\n",
        "# 1. Model Class: In PyTorch, you typically define a custom neural network model by subclassing the `torch.nn.Module` class.\n",
        "# This allows you to create a custom architecture by defining the layers and their connections.\n",
        "# 2. Layers: Neural networks are composed of layers, which are instances of `torch.nn.Module` subclasses.\n",
        "# Common layers include fully connected (linear) layers, convolutional layers, recurrent layers, and activation functions.\n",
        "# You can stack multiple layers to create a deep network.\n",
        "# 3. Forward Method: The `forward` method defines the forward pass of the network, specifying how the input data flows through the layers.\n",
        "# This method takes input data as an argument and returns the output of the network.\n",
        "# 4. Loss Function: The loss function measures the difference between the predicted output and the true target values.\n",
        "# Common loss functions include mean squared error (MSE) for regression tasks and cross-entropy loss for classification tasks.\n",
        "# 5. Optimizer: The optimizer updates the model's parameters based on the gradients computed during backpropagation.\n",
        "# Common optimizers include stochastic gradient descent (SGD), Adam, and RMSprop.\n",
        "# 6. Training Loop: The training loop iterates over the dataset, performing forward passes, computing the loss,\n",
        "# calculating gradients, and updating the model parameters using the optimizer.\n",
        "# 7. Evaluation: After training, you can evaluate the model's performance on a validation or test dataset to assess its accuracy and generalization.\n",
        "\n",
        "# Here's a simple example of a basic PyTorch neural network structure for a feedforward neural network:\n",
        "# ```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style='whitegrid')\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# Generate synthetic data for binary classification\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train_tensor = torch.FloatTensor(X_train)\n",
        "y_train_tensor = torch.LongTensor(y_train)\n",
        "X_test_tensor = torch.FloatTensor(X_test)\n",
        "y_test_tensor = torch.LongTensor(y_test)\n",
        "# Define the neural network model\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)  # First fully connected layer\n",
        "        self.fc2 = nn.Linear(64, 32)          # Second fully connected layer\n",
        "        self.fc3 = nn.Linear(32, 2)           # Output layer (2 classes)\n",
        "        self.relu = nn.ReLU()                 # Activation function\n",
        "        self.softmax = nn.Softmax(dim=1)      # Softmax activation for output layer\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)                       # Pass input through first layer\n",
        "        x = self.relu(x)                     # Apply ReLU activation\n",
        "        x = self.fc2(x)                       # Pass through second layer\n",
        "        x = self.relu(x)                     # Apply ReLU activation\n",
        "        x = self.fc3(x)                       # Pass through output layer\n",
        "        x = self.softmax(x)                   # Apply softmax activation\n",
        "        return x\n",
        "# Create an instance of the model\n",
        "input_size = X_train.shape[1]  # Number of features\n",
        "model = SimpleNN(input_size)\n",
        "# Define the loss function and optimizer\n",
        "loss_function = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "batch_size = 32\n",
        "train_losses = []\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    permutation = torch.randperm(X_train_tensor.size(0))  # Shuffle the training data\n",
        "    for i in range(0, X_train_tensor.size(0), batch_size):\n",
        "        indices = permutation[i:i + batch_size]  # Get the batch indices\n",
        "        batch_x, batch_y = X_train_tensor[indices], y_train_tensor[indices]  # Get the batch data\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        outputs = model(batch_x)  # Forward pass\n",
        "        loss = loss_function(outputs, batch_y)  # Compute the loss\n",
        "        loss.backward()  # Backward pass (compute gradients)\n",
        "        optimizer.step()  # Update the model parameters\n",
        "        train_losses.append(loss.item())  # Store the loss for plotting\n",
        "    # Print the training loss every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "# Plot the training loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss Over Iterations')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Evaluate the model on the test set\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test_tensor)  # Forward pass on test data\n",
        "    _, predicted = torch.max(test_outputs, 1)  # Get the predicted class labels\n",
        "    accuracy = accuracy_score(y_test_tensor.numpy(), predicted.numpy())  # Calculate accuracy\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')\n",
        "# ```\n",
        "# In this example, we create a simple feedforward neural network with two hidden layers using PyTorch.\n",
        "# We define the model architecture by subclassing `torch.nn.Module` and implementing the `forward` method.\n",
        "# The model is trained using the Adam optimizer and cross-entropy loss function.\n",
        "# We also visualize the training loss over iterations and evaluate the model's accuracy on a test dataset.\n",
        "# This structure can be adapted and expanded for more complex architectures and tasks, such as convolutional neural networks (CNNs) or recurrent neural networks (RNNs).\n",
        "# PyTorch provides a flexible and intuitive framework for building and training neural networks, making it a popular choice among researchers and developers.\n",
        "# With its dynamic computation graph and extensive community support, PyTorch enables users to experiment with various architectures and techniques easily.\n",
        "# Whether you are working on computer vision, natural language processing, or other machine learning tasks,\n",
        "# PyTorch provides the tools and resources you need to succeed.\n",
        "# By following the basic structure outlined above, you can create and train your own neural networks using PyTorch.\n",
        "# This structure serves as a foundation for building more complex models and experimenting with different architectures and techniques.\n",
        "# With its rich ecosystem of libraries and tools, PyTorch empowers you to tackle a wide range of machine learning tasks,\n",
        "# from research to production.\n",
        "# Whether you are a beginner or an experienced practitioner, PyTorch offers a user-friendly environment for exploring the world of deep learning.\n",
        "# With its flexibility and ease of use, PyTorch has become one of the leading frameworks in the deep learning ecosystem.\n",
        "# By leveraging the power of PyTorch, you can unlock new possibilities in machine learning and deep learning,\n",
        "# enabling you to tackle complex problems and drive innovation in your projects.\n",
        "# Whether you are building cutting-edge models, conducting research, or deploying applications in production,\n",
        "# PyTorch provides the tools and resources you need to succeed.\n",
        "# With its dynamic computation graph and extensive community support, PyTorch enables users to experiment with various architectures and techniques easily.\n",
        "# Whether you are working on computer vision, natural language processing, or other machine learning tasks,\n",
        "# PyTorch provides the tools and resources you need to succeed.\n",
        "# By following the basic structure outlined above, you can create and train your own neural networks using PyTorch.\n",
        "# This structure serves as a foundation for building more complex models and experimenting with different architectures and techniques.\n",
        "# With its rich ecosystem of libraries and tools, PyTorch empowers you to tackle a wide range of machine learning tasks,\n",
        "# from research to production.\n",
        "# Whether you are a beginner or an experienced practitioner, PyTorch offers a user-friendly environment for exploring the world of deep learning.\n",
        "# With its flexibility and ease of use, PyTorch has become one of the leading frameworks in the deep learning ecosystem.\n",
        "# By leveraging the power of PyTorch, you can unlock new possibilities in machine learning and deep learning,\n",
        "# enabling you to tackle complex problems and drive innovation in your projects.\n",
        "# Whether you are building cutting-edge models, conducting research, or deploying applications in production,\n",
        "# PyTorch provides the tools and resources you need to succeed.\n",
        "# With its dynamic computation graph and extensive community support, PyTorch enables users to experiment with various architectures and techniques easily.\n",
        "# Whether you are working on computer vision, natural language processing, or other machine learning tasks,\n",
        "# PyTorch provides the tools and resources you need to succeed.\n",
        "# By following the basic structure outlined above, you can create and train your own neural networks using PyTorch.\n",
        "# This structure serves as a foundation for building more complex models and experimenting with different architectures and techniques.\n",
        "# With its rich ecosystem of libraries and tools, PyTorch empowers you to tackle a wide range of machine learning tasks,\n",
        "# from research to production.\n",
        "# Whether you are a beginner or an experienced practitioner, PyTorch offers a user-friendly environment for exploring the world of deep learning.\n",
        "# With its flexibility and ease of use, PyTorch has become one of the leading frameworks in the deep learning ecosystem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "141a9e71",
      "metadata": {
        "id": "141a9e71"
      },
      "outputs": [],
      "source": [
        "# 13. What is the significance of tensors in PyTorch?\n",
        "\n",
        "# Answer:\n",
        "# Tensors are the fundamental data structure in PyTorch, similar to arrays or matrices in NumPy.\n",
        "# They are multi-dimensional arrays that can represent data of various types, including scalars, vectors, matrices, and higher-dimensional data.\n",
        "# The significance of tensors in PyTorch includes:\n",
        "# 1. Data Representation: Tensors provide a flexible and efficient way to represent data in PyTorch.\n",
        "# They can hold data of different types, including integers, floats, and booleans.\n",
        "# Tensors can also have varying dimensions, allowing for the representation of complex data structures such as images, text, and time series.\n",
        "# 2. GPU Acceleration: PyTorch tensors can be easily moved between CPU and GPU memory, enabling efficient computation on GPUs.\n",
        "# This allows for faster training and inference of deep learning models, especially for large datasets and complex architectures.\n",
        "# PyTorch automatically handles the transfer of tensors between CPU and GPU, making it easy to leverage hardware acceleration.\n",
        "# 3. Automatic Differentiation: Tensors in PyTorch support automatic differentiation, which is essential for training neural networks.\n",
        "# When you perform operations on tensors, PyTorch keeps track of the computation graph and can compute gradients automatically.\n",
        "# This feature is crucial for implementing backpropagation and optimizing model parameters during training.\n",
        "# 4. Mathematical Operations: PyTorch provides a wide range of mathematical operations that can be performed on tensors,\n",
        "# including element-wise operations, matrix multiplication, and reductions (e.g., sum, mean).\n",
        "# These operations are optimized for performance and can be executed on both CPU and GPU.\n",
        "# 5. Broadcasting: Tensors in PyTorch support broadcasting, which allows for automatic expansion of dimensions during operations.\n",
        "# This feature simplifies the implementation of mathematical operations on tensors of different shapes and sizes.\n",
        "# 6. Interoperability: PyTorch tensors can be easily converted to and from NumPy arrays, allowing for seamless integration with the NumPy ecosystem.\n",
        "# This interoperability is beneficial for data preprocessing, visualization, and using existing NumPy libraries.\n",
        "# 7. Flexibility: Tensors provide a flexible framework for defining custom data structures and operations.\n",
        "# PyTorch allows users to create custom tensor operations and extend the functionality of the library.\n",
        "# This flexibility is particularly useful for researchers and developers working on novel algorithms and architectures.\n",
        "# 8. Support for Distributed Computing: PyTorch tensors can be used in distributed computing environments,\n",
        "# enabling parallel processing and training across multiple devices or nodes.\n",
        "# This is essential for scaling up deep learning models and handling large datasets.\n",
        "# 9. Rich Ecosystem: PyTorch has a rich ecosystem of libraries and tools built around tensors,\n",
        "# including libraries for computer vision (e.g., torchvision), natural language processing (e.g., torchtext),\n",
        "# and reinforcement learning (e.g., torchrl).\n",
        "# These libraries provide pre-built models, datasets, and utilities that leverage the power of tensors.\n",
        "# 10. Community Support: PyTorch has a large and active community that contributes to the development of libraries, tutorials, and resources.\n",
        "# This community support enhances the usability and accessibility of tensors in PyTorch, making it easier for users to learn and experiment with deep learning.\n",
        "# Overall, tensors are a fundamental building block of PyTorch and play a crucial role in enabling efficient computation,\n",
        "# automatic differentiation, and flexible data representation.\n",
        "# They are essential for implementing deep learning models and performing various mathematical operations,\n",
        "# making PyTorch a powerful and versatile framework for machine learning and deep learning applications.\n",
        "# By leveraging the capabilities of tensors, users can build and train complex neural networks,\n",
        "# experiment with different architectures, and tackle a wide range of machine learning tasks.\n",
        "# Whether you are working on computer vision, natural language processing, or other domains,\n",
        "# PyTorch tensors provide the tools and resources you need to succeed.\n",
        "# With their flexibility, efficiency, and support for GPU acceleration,\n",
        "# tensors enable users to unlock new possibilities in deep learning and drive innovation in their projects.\n",
        "# Whether you are a beginner or an experienced practitioner, PyTorch tensors offer a user-friendly environment for exploring the world of deep learning.\n",
        "# With their rich ecosystem of libraries and tools, PyTorch empowers you to tackle a wide range of machine learning tasks,\n",
        "# from research to production."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e82ca5ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e82ca5ba",
        "outputId": "c89bf3b2-9401-48ca-d857-0831156d9111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# 14. What is the difference between torch.Tensor and torch.cuda.Tensor in PyTorch?\n",
        "\n",
        "# Answer:\n",
        "# 1. torch.Tensor:\n",
        "# - `torch.Tensor` is the default tensor type in PyTorch.\n",
        "# - It is created on the CPU by default and performs computations on the CPU.\n",
        "# - You can create a `torch.Tensor` using functions like `torch.tensor()`, `torch.zeros()`, `torch.ones()`, etc.\n",
        "# - Example:\n",
        "# ```python\n",
        "# import torch\n",
        "tensor_cpu = torch.tensor([1, 2, 3])\n",
        "print(tensor_cpu.device)  # Output: cpu\n",
        "# ```\n",
        "\n",
        "# 2. torch.cuda.Tensor:\n",
        "# - `torch.cuda.Tensor` is a tensor that resides on the GPU and performs computations on the GPU.\n",
        "# - It is created by explicitly moving a tensor to the GPU using `.to('cuda')` or `.cuda()` methods.\n",
        "# - Example:\n",
        "# ```python\n",
        "tensor_gpu = tensor_cpu.to('cuda')  # Move tensor to GPU\n",
        "print(tensor_gpu.device)  # Output: cuda:0 (or the GPU device index)\n",
        "# ```\n",
        "\n",
        "# Key Differences:\n",
        "# - `torch.Tensor` operates on the CPU, while `torch.cuda.Tensor` operates on the GPU.\n",
        "# - GPU tensors (`torch.cuda.Tensor`) enable faster computations for large-scale data and deep learning tasks by leveraging GPU acceleration.\n",
        "# - Operations between tensors must be on the same device (CPU or GPU). Mixing CPU and GPU tensors will result in an error.\n",
        "# - Example of an error:\n",
        "# # ```python\n",
        "# tensor_cpu + tensor_gpu  # This will raise a RuntimeError\n",
        "# # ```\n",
        "\n",
        "# To summarize:\n",
        "# - Use `torch.Tensor` for CPU-based computations.\n",
        "# - Use `torch.cuda.Tensor` for GPU-based computations to take advantage of hardware acceleration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4188694f",
      "metadata": {
        "id": "4188694f"
      },
      "outputs": [],
      "source": [
        "# 15. What is the purpose of the torch.optim module in PyTorch?\n",
        "\n",
        "# Answer:\n",
        "import torch\n",
        "\n",
        "# The purpose of torch.optim module:\n",
        "# 1. Gradient-Based Optimization:\n",
        "#    - The module provides implementations of popular gradient-based optimization algorithms, such as SGD, Adam, RMSprop, etc.\n",
        "#    - These algorithms use gradients computed during backpropagation to update model parameters.\n",
        "\n",
        "# 2. Parameter Updates:\n",
        "#    - The optimizers handle the logic for updating model parameters based on gradients and learning rates.\n",
        "#    - This simplifies the training loop, as you don't need to manually update parameters.\n",
        "\n",
        "# 3. Learning Rate Scheduling:\n",
        "#    - The module supports learning rate schedulers, which adjust the learning rate during training.\n",
        "#    - This helps improve convergence and performance.\n",
        "\n",
        "# 4. Flexibility:\n",
        "#    - The module allows customization of optimization settings, such as per-parameter learning rates and weight decay.\n",
        "\n",
        "# Example of using torch.optim:\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define a simple model\n",
        "model = nn.Linear(10, 1)\n",
        "\n",
        "# Define a loss function\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Define an optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Dummy data\n",
        "inputs = torch.randn(5, 10)\n",
        "targets = torch.randn(5, 1)\n",
        "\n",
        "# Training step\n",
        "optimizer.zero_grad()  # Clear gradients\n",
        "outputs = model(inputs)  # Forward pass\n",
        "loss = criterion(outputs, targets)  # Compute loss\n",
        "loss.backward()  # Backward pass (compute gradients)\n",
        "optimizer.step()  # Update parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e64602f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e64602f",
        "outputId": "184f947a-c35b-4772-b23c-9e42628989d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sigmoid Output: tensor([0.2689, 0.5000, 0.7311])\n",
            "ReLU Output: tensor([0., 0., 1.])\n",
            "Tanh Output: tensor([-0.7616,  0.0000,  0.7616])\n",
            "Softmax Output: tensor([0.6590, 0.2424, 0.0986])\n",
            "Leaky ReLU Output: tensor([-0.0100,  0.0000,  1.0000])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 16. What are some common activation functions used in neural networks?\n",
        "\n",
        "# Answer:\n",
        "# Some common activation functions used in neural networks include:\n",
        "\n",
        "# # 1. Sigmoid:\n",
        "# # The sigmoid function maps input values to a range between 0 and 1.\n",
        "# # It is often used in the output layer for binary classification problems.\n",
        "import torch.nn.functional as F\n",
        "\n",
        "x = torch.tensor([-1.0, 0.0, 1.0])\n",
        "sigmoid_output = torch.sigmoid(x)\n",
        "print(\"Sigmoid Output:\", sigmoid_output)\n",
        "\n",
        "# 2. ReLU (Rectified Linear Unit):\n",
        "# ReLU replaces negative values with 0 and keeps positive values unchanged.\n",
        "# It is widely used in hidden layers of neural networks.\n",
        "relu_output = F.relu(x)\n",
        "print(\"ReLU Output:\", relu_output)\n",
        "\n",
        "# 3. Tanh (Hyperbolic Tangent):\n",
        "# Tanh maps input values to a range between -1 and 1.\n",
        "# It is often used in hidden layers when the data is centered around zero.\n",
        "tanh_output = torch.tanh(x)\n",
        "print(\"Tanh Output:\", tanh_output)\n",
        "\n",
        "# 4. Softmax:\n",
        "# Softmax is used in the output layer for multi-class classification problems.\n",
        "# It converts logits into probabilities that sum to 1.\n",
        "logits = torch.tensor([2.0, 1.0, 0.1])\n",
        "softmax_output = F.softmax(logits, dim=0)\n",
        "print(\"Softmax Output:\", softmax_output)\n",
        "\n",
        "# 5. Leaky ReLU:\n",
        "# Leaky ReLU allows a small gradient for negative values instead of setting them to 0.\n",
        "leaky_relu_output = F.leaky_relu(x, negative_slope=0.01)\n",
        "print(\"Leaky ReLU Output:\", leaky_relu_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1102ade5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1102ade5",
        "outputId": "62240a64-b88b-4f84-c5b4-9a857999ac25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CustomModel(\n",
            "  (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=20, out_features=1, bias=True)\n",
            ")\n",
            "Sequential(\n",
            "  (0): Linear(in_features=10, out_features=20, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=20, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# 17. What is the difference between torch.nn.Module and torch.nn.Sequential in PyTorch?\n",
        "\n",
        "# Answer:\n",
        "# torch.nn.Module:\n",
        "# - `torch.nn.Module` is the base class for all neural network models in PyTorch.\n",
        "# - It allows you to define custom models by implementing the `__init__` and `forward` methods.\n",
        "# - You have full control over the architecture and forward pass logic.\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "# Example using torch.nn.Module\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(10, 20)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(20, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "custom_model = CustomModel()\n",
        "print(custom_model)\n",
        "\n",
        "# torch.nn.Sequential:\n",
        "# - `torch.nn.Sequential` is a simpler way to define models by stacking layers in order.\n",
        "# - It is useful for straightforward architectures where the forward pass is just a sequence of layers.\n",
        "\n",
        "# Example using torch.nn.Sequential\n",
        "sequential_model = nn.Sequential(\n",
        "    nn.Linear(10, 20),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 1)\n",
        ")\n",
        "print(sequential_model)\n",
        "\n",
        "# Key Differences:\n",
        "# 1. Flexibility:\n",
        "#    - `torch.nn.Module` allows for more flexibility in defining complex architectures and custom forward passes.\n",
        "#    - `torch.nn.Sequential` is limited to sequentially stacking layers.\n",
        "\n",
        "# 2. Use Case:\n",
        "#    - Use `torch.nn.Module` for custom models with non-linear or branching architectures.\n",
        "#    - Use `torch.nn.Sequential` for simple, linear architectures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8173fcc",
      "metadata": {
        "id": "d8173fcc"
      },
      "outputs": [],
      "source": [
        "# 18. How can you monitor training progress in TensorFlow 2.0?\n",
        "\n",
        "# Answer:\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "import datetime\n",
        "\n",
        "# Generate some random data for demonstration\n",
        "x_train = tf.random.normal((1000, 20))\n",
        "y_train = tf.random.uniform((1000,), maxval=2, dtype=tf.int32)\n",
        "\n",
        "# Create a simple model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(20,)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Set up TensorBoard callback\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# Set up ModelCheckpoint callback\n",
        "checkpoint_callback = ModelCheckpoint(filepath='model_checkpoint.h5', save_best_only=True)\n",
        "\n",
        "# Train the model with callbacks\n",
        "model.fit(x_train, y_train,\n",
        "          epochs=10,\n",
        "          batch_size=32,\n",
        "          validation_split=0.2,\n",
        "          callbacks=[tensorboard_callback, checkpoint_callback])\n",
        "\n",
        "# # To view TensorBoard, run the following command in your terminal:\n",
        "# # tensorboard --logdir=logs/fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "609698eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "609698eb",
        "outputId": "3a265cc7-9eec-461d-fa05-50d37ac365cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# 19. How does the Keras API fit into TensorFlow 2.0?\n",
        "\n",
        "# Answer:\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# The Keras API in TensorFlow 2.0 provides:\n",
        "# 1. Simplified Model Building:\n",
        "#    - Keras offers two main ways to build models: Sequential API and Functional API.\n",
        "#    - The Sequential API is used for simple, linear stacks of layers.\n",
        "#    - The Functional API is used for more complex architectures with multiple inputs/outputs.\n",
        "\n",
        "\n",
        "# Example of Sequential API\n",
        "sequential_model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(20,)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Example of Functional API\n",
        "inputs = Input(shape=(20,))\n",
        "x = Dense(64, activation='relu')(inputs)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "functional_model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# 2. Integrated Training and Evaluation:\n",
        "#    - Keras provides methods like `fit`, `evaluate`, and `predict` for training, evaluating, and making predictions.\n",
        "\n",
        "sequential_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Train the model\n",
        "# sequential_model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# 3. Preprocessing and Utilities:\n",
        "#    - Keras includes utilities for data preprocessing, augmentation, and loading datasets.\n",
        "\n",
        "\n",
        "# Load and preprocess data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28 * 28) / 255.0\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "# 4. Callbacks:\n",
        "#    - Keras supports callbacks like TensorBoard, ModelCheckpoint, and EarlyStopping for monitoring and improving training.\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# 5. Interoperability:\n",
        "#    - Keras models are fully integrated with TensorFlow, allowing seamless use of TensorFlow features like `tf.data` and `tf.function`.\n",
        "\n",
        "# 6. Deployment:\n",
        "#    - Keras models can be easily exported and deployed using TensorFlow Serving, TensorFlow Lite, or TensorFlow.js."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b532dba",
      "metadata": {
        "id": "5b532dba"
      },
      "outputs": [],
      "source": [
        "# 20. What is an example of a deep learning project that can be implemented using TensorFlow 2.0?\n",
        "\n",
        "# Answer:\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "y_train, y_test = to_categorical(y_train), to_categorical(y_test)  # One-hot encode labels\n",
        "\n",
        "# Define the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')  # 10 classes for CIFAR-10\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f354edc4",
      "metadata": {
        "id": "f354edc4"
      },
      "outputs": [],
      "source": [
        "# 21.What is the main advantage of using pre-trained models in TensorFlow and PyTorch?\n",
        "\n",
        "# Answer:\n",
        "from tensorflow.keras.applications import VGG16\n",
        "import torch\n",
        "\n",
        "# Example of using a pre-trained model in TensorFlow\n",
        "\n",
        "# Load the VGG16 model pre-trained on ImageNet\n",
        "vgg16_model = VGG16(weights='imagenet')\n",
        "\n",
        "# Display the model architecture\n",
        "vgg16_model.summary()\n",
        "\n",
        "# Example of using a pre-trained model in PyTorch\n",
        "import torchvision.models as models\n",
        "\n",
        "# Load the ResNet18 model pre-trained on ImageNet\n",
        "resnet18_model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Display the model architecture\n",
        "print(resnet18_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Practical\n"
      ],
      "metadata": {
        "id": "e8rZQqnwKGmA"
      },
      "id": "e8rZQqnwKGmA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06620160",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06620160",
        "outputId": "6caed63c-eee7-45d8-e3f0-88556592948b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.0 (from versions: 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1, 2.15.1, 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# 1. How do you install and verify that TensorFlow 2.0 was installed successfully?\n",
        "\n",
        "!pip install tensorflow==2.0\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. How can you define a simple function in TensorFlow 2.0 to perform addition?\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def tensor_addition(x,y):\n",
        "  x=tf.constant(x)\n",
        "  y=tf.constant(y)\n",
        "\n",
        "  return tf.add(x,y)\n",
        "\n",
        "result = tensor_addition(5, 3)\n",
        "print(result.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUwpf57BKYEh",
        "outputId": "53b0dfee-271f-4201-d8d1-4ab27e43cf04"
      },
      "id": "vUwpf57BKYEh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. How can you create a simple neural network in TensorFlow 2.0 with one hidden layer?\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the model\n",
        "model = Sequential(\n",
        "    [\n",
        "        Dense(16, activation=\"relu\", input_shape=(10,)),\n",
        "        Dense(1, activation=\"sigmoid\")\n",
        "\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compile thr model\n",
        "model.compile(\n",
        "    optimizer = \"adam\",\n",
        "    loss = \"binary_crossentropy\",\n",
        "    metrics = [\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "lktyA8YSKsIq",
        "outputId": "0aad9f59-919d-49b4-bebb-96be1bf33c19"
      },
      "id": "lktyA8YSKsIq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m176\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m193\u001b[0m (772.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">193</span> (772.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m193\u001b[0m (772.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">193</span> (772.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. How can you visualize the training progress using TensorFlow and Matplotlib?\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1 create synthetic data (1000 sample, 10 features)\n",
        "X_train = np.random.rand(1000, 10)\n",
        "y_train = np.random.randint(0, 2, size=(1000, 1))\n",
        "\n",
        "# Step 2: Build the model\n",
        "model = Sequential(\n",
        "    [\n",
        "        Dense(16, activation=\"relu\", input_shape=(10,)),\n",
        "        Dense(1, activation=\"sigmoid\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Step 4: Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Step 5: Visualize training history (accuracy and loss)\n",
        "plt.figure(figsize=(20, 8))\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
        "plt.title(\"Accuracy over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.title(\"Loss over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iEVv2MnNK1Rn"
      },
      "id": "iEVv2MnNK1Rn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"Is CUDA available? {tf.test.is_built_with_cuda()}\")\n",
        "print(f\"Number of CUDA-enabled GPUs: {len(tf.config.list_physical_devices('GPU'))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcOgdWeviOKs",
        "outputId": "60ae3027-46f6-4dae-acd8-161549aac50b"
      },
      "id": "BcOgdWeviOKs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.18.0\n",
            "Is CUDA available? True\n",
            "Number of CUDA-enabled GPUs: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. How do you install PyTorch and verify the PyTorch installation?\n",
        "\n",
        "!pip3 install torch torchvision torchaudio\n",
        "\n",
        "# Verify PyTorch installation\n",
        "import torch\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available()) # Check for CUDA availability\n",
        "print(torch.version.cuda) # Check CUDA version\n",
        "x = torch.rand(5, 3)\n",
        "x\n"
      ],
      "metadata": {
        "id": "sO-7sKS3SM9X"
      },
      "id": "sO-7sKS3SM9X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. How do you create a simple neural network in PyTorch?\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the network architecture\n",
        "class SimpleNN(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim) :\n",
        "      super(SimpleNN,self).__init__()\n",
        "      self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "      self.relu = nn.ReLU()\n",
        "      self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.fc1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.fc2(out)\n",
        "    return out\n",
        "\n",
        "# Initialize the model\n",
        "\n",
        "input_dim = 10\n",
        "hidden_dim = 32\n",
        "output_dim = 1\n",
        "\n",
        "model = SimpleNN(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "# Loss function and optimizers\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "\n",
        "X = torch.randn(100, input_dim)\n",
        "y = torch.randint(0, 2,(100,1)).float()\n",
        "\n",
        "# trainig loop\n",
        "for epoch in range(100):\n",
        "  outputs = model(X)\n",
        "  loss = criterion(outputs, y)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if (epoch + 1 )% 10 == 0:\n",
        "    print(f\"Epoch [{epoch+1}/100], Loss: {loss.item():.4f}\\n\")\n",
        "\n",
        "# Step 6: Make predictions\n",
        "with torch.no_grad():\n",
        "  test_data = torch.randn(5, input_dim)\n",
        "  preds = torch.sigmoid(model(test_data))\n",
        "  print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNA3cmXMXZbo",
        "outputId": "4bde5b9a-868e-4cbc-f4ce-fad106ad3e40"
      },
      "id": "dNA3cmXMXZbo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.6600\n",
            "\n",
            "Epoch [20/100], Loss: 0.6476\n",
            "\n",
            "Epoch [30/100], Loss: 0.6355\n",
            "\n",
            "Epoch [40/100], Loss: 0.6234\n",
            "\n",
            "Epoch [50/100], Loss: 0.6112\n",
            "\n",
            "Epoch [60/100], Loss: 0.5988\n",
            "\n",
            "Epoch [70/100], Loss: 0.5858\n",
            "\n",
            "Epoch [80/100], Loss: 0.5721\n",
            "\n",
            "Epoch [90/100], Loss: 0.5577\n",
            "\n",
            "Epoch [100/100], Loss: 0.5428\n",
            "\n",
            "tensor([[0.4723],\n",
            "        [0.3572],\n",
            "        [0.4598],\n",
            "        [0.5070],\n",
            "        [0.7199]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7.  How do you define a loss function and optimizer in PyTorch?\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.MSELoss()  # Example: Mean Squared Error loss\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) # Example: Adam optimizer"
      ],
      "metadata": {
        "id": "U6sUUdUQcrej"
      },
      "id": "U6sUUdUQcrej",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8.  How do you implement a custom loss function in PyTorch?\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CustomLoss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CustomLoss, self).__init__()\n",
        "\n",
        "  def forward(self, outputs, targets):\n",
        "    loss = torch.mean(torch.abs(outputs - targets))\n",
        "    return\n",
        "# for i.e\n",
        "\n",
        "criterion = CustomLoss()\n",
        "outputs = torch.randn(10,1)\n",
        "targets = torch.randn(10,1)\n",
        "loss = criterion(outputs, targets)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ekk_xwQ-eD9s",
        "outputId": "16f69b72-1bde-412a-f3fc-8c293f9964ce"
      },
      "id": "Ekk_xwQ-eD9s",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. How do you save and load a TensorFlow model?\n",
        "\n",
        "\n",
        "# save model\n",
        "model.save(\"deep learning framework model.h5\")\n",
        "\n",
        "# load model\n",
        "model = tf.keras.models.load_model(\"deep learning framework model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alEvChrLfn91",
        "outputId": "b73c7a12-69cc-4070-a150-f44d71189957"
      },
      "id": "alEvChrLfn91",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8L1OQyqyfYEl"
      },
      "id": "8L1OQyqyfYEl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WgYa0_MtfaJ_"
      },
      "id": "WgYa0_MtfaJ_",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}